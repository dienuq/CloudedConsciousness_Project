{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWLR8aXrPUdO",
        "outputId": "2d6879d2-7287-4b0d-8941-0bd5b1ca0f0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jan 27 19:57:49 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   66C    P8              11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yedM6IP5PQSE",
        "outputId": "2de78313-e71f-4fed-e98a-d035fb8756d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 13.6 gigabytes of available RAM\n",
            "\n",
            "Not using a high-RAM runtime\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luOGQrbWq1vQ",
        "outputId": "4e3f59e7-2fc6-454f-a015-394ec682e022"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-3d64d02c-a655-010c-f4d5-7a1bfcf20f2b)\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "_ROKVwRQTWa_",
        "outputId": "2d3761a0-7da2-4091-ace9-e67e4bf1a014"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import torch\n",
        "torch. __version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BC_1rOgPSyN7",
        "outputId": "65a38293-f2d4-4907-c5e5-76778b038926"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/cu113/torch_stable.html\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.10.0+cu113 (from versions: 1.11.0, 1.11.0+cu113, 1.12.0, 1.12.0+cu113, 1.12.1, 1.12.1+cu113, 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.10.0+cu113\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.10.0+cu113 torchvision==0.11.1+cu113 torchaudio===0.10.0+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "OcnIWmML_-PT",
        "outputId": "acd115d3-0417-463b-9c99-c4080a5ea540"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n",
            "Collecting setuptools==59.5.0\n",
            "  Downloading setuptools-59.5.0-py3-none-any.whl (952 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m952.4/952.4 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: setuptools\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 67.7.2\n",
            "    Uninstalling setuptools-67.7.2:\n",
            "      Successfully uninstalled setuptools-67.7.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "arviz 0.15.1 requires setuptools>=60.0.0, but you have setuptools 59.5.0 which is incompatible.\n",
            "cvxpy 1.3.3 requires setuptools>65.5.1, but you have setuptools 59.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed setuptools-59.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "pkg_resources",
                  "setuptools"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!python --version\n",
        "\n",
        "!pip install setuptools==59.5.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0G01YdqrAV-",
        "outputId": "a12bb145-ebbe-4c5a-d173-4958d5adefe4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGizh6S0ryul",
        "outputId": "638cc04a-d594-4923-89fa-149d429f7428"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/CC3_stylegan\n"
          ]
        }
      ],
      "source": [
        "%cd \"/content/drive/MyDrive/CC3_stylegan/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8zlYD_GrzZb",
        "outputId": "294fbb11-d197-4434-88c9-7ae6c6f8051f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'stylegan3-fun'...\n",
            "remote: Enumerating objects: 701, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 701 (delta 0), reused 2 (delta 0), pack-reused 698\u001b[K\n",
            "Receiving objects: 100% (701/701), 4.43 MiB | 14.18 MiB/s, done.\n",
            "Resolving deltas: 100% (446/446), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/PDillis/stylegan3-fun.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACZSfm-CmQGI",
        "outputId": "1519d74f-88be-49c9-a744-df75910d302a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/CC3_stylegan/stylegan3-fun\n"
          ]
        }
      ],
      "source": [
        "%cd stylegan3-fun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZAjaWoymWhe",
        "outputId": "d53cb4bd-0e50-4f70-b440-86237b0323dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg_spectra.py\t\t    network_features.py   out_trickster\n",
            "calc_metrics.py\t\t    out\t\t\t  projector.py\n",
            "dataset_tool.py\t\t    out_anima\t\t  __pycache__\n",
            "discriminator_synthesis.py  out_animus\t\t  pytorch_ssim\n",
            "dnnlib\t\t\t    out_child\t\t  README.md\n",
            "Dockerfile\t\t    out_father\t\t  sightseeding.py\n",
            "docs\t\t\t    out_mother\t\t  style_mixing.py\n",
            "environment.yml\t\t    out_persona\t\t  torch_utils\n",
            "generate.py\t\t    out_self\t\t  training\n",
            "gen_images.py\t\t    out_shadow\t\t  training-runs\n",
            "gen_video.py\t\t    out_shadow1\t\t  training-runs_skyscraper\n",
            "gui_utils\t\t    out_shadow15_4\t  train.py\n",
            "legacy.py\t\t    out_shadow18\t  visualizer.py\n",
            "LICENSE.txt\t\t    out_skyscraper\t  visual_reactive.py\n",
            "metrics\t\t\t    out_skyscraper_gen\t  viz\n",
            "multimodal_truncation.py    out_skyscraper_img01  weights.h5\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOapnEP2uOBN",
        "outputId": "14697862-cd4c-4ed9-8b7b-b7d6e02aa1e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ninja\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/307.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m286.7/307.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ninja\n",
            "Successfully installed ninja-1.11.1.1\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.10/dist-packages (0.4.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg) (59.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install ninja\n",
        "!pip install imageio-ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKmnP-nqn6uc"
      },
      "outputs": [],
      "source": [
        "!python dataset_tool.py --source=/content/drive/MyDrive/Archetypes_Dataset/AnimaPNG/Anima1024 --dest=/content/drive/MyDrive/Archetypes_Dataset/anima-1024x1024.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfCK5RJitmTT"
      },
      "outputs": [],
      "source": [
        "!python gen_images.py --outdir=out_child --trunc=0.5 --seeds=1-5 \\\n",
        "    --network=/content/drive/MyDrive/CC3_stylegan/stylegan3-fun/training-runs/00026-stylegan3-t-child-1024x1024-gpus1-batch16-gamma32-resume_custom/network-snapshot-000100.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03FSoBbjnpOB",
        "outputId": "c01880ba-e913-4196-8e4e-4b1892534fca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading networks from \"/content/drive/MyDrive/CC3_stylegan/stylegan3-fun/training-runs/00023-stylegan3-t-trickster-1024x1024-gpus1-batch16-gamma32-resume_custom/network-snapshot-000100.pkl\"...\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
            "100% 10920/10920 [08:15<00:00, 22.03it/s]\n"
          ]
        }
      ],
      "source": [
        "!python gen_video.py --output=out_trickster/1.mp4 --trunc=0.5 --seeds=0-90 \\\n",
        "    --network=/content/drive/MyDrive/CC3_stylegan/stylegan3-fun/training-runs/00023-stylegan3-t-trickster-1024x1024-gpus1-batch16-gamma32-resume_custom/network-snapshot-000100.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pIy9M1wr5-2Z",
        "outputId": "61715b28-0744-419e-d014-f1a6378a85d5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'NVIDIA A100-SXM4-40GB'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "import torch\n",
        "torch.__version__ # Get PyTorch and CUDA version\n",
        "torch.cuda.is_available() # Check that CUDA works\n",
        "torch.cuda.device_count() # Check how many CUDA capable devices you have\n",
        "\n",
        "# Print device human readable names\n",
        "torch.cuda.get_device_name(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d7jEwCz6fzC",
        "outputId": "ca42f5c8-7c1a-466b-900e-ff10f16bb1c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/CC3_stylegan/stylegan3-fun\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqaD7CEnWq-C",
        "outputId": "dd01ee0e-f3e9-48d0-d6ee-84979812be00"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.distribute.one_device_strategy.OneDeviceStrategy at 0x7f982b16cb80>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "if len(devices) > 1:\n",
        "  strategy = tf.distribute.MirroredStrategy()\n",
        "else:\n",
        "  strategy = tf.distribute.OneDeviceStrategy(\"gpu:0\")\n",
        "\n",
        "strategy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szrseeRJprqp"
      },
      "outputs": [],
      "source": [
        "!python train.py --outdir=training-runs --cfg=stylegan3-t --data=/content/drive/MyDrive/Archetypes_Dataset/shadow-1024x1024.zip --gpus=1 --batch=16 --gamma=32 --mirror=1 --kimg=100 --snap=1 --resume=https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-t-metfaces-1024x1024.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFzEgXyOfo3-"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v91hPMuRAzdx",
        "outputId": "a7d62dea-4717-41e6-8e52-4529635eed02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading networks from \"/content/drive/MyDrive/CC3_stylegan/stylegan3-fun/training-runs/00018-stylegan3-t-shadow-1024x1024-gpus1-batch16-gamma32-resume_custom/network-snapshot-000072.pkl\"...\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Projecting in W+ latent space...\n",
            "Starting from W midpoint using 10000 samples...\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
            "step 700/700: dist 3.9153850e-01 | loss 3.9153850e-01\n",
            "Elapsed time: 1m 11s\n",
            "Creating output directory...\n",
            "Saving projection results...\n"
          ]
        }
      ],
      "source": [
        "!python projector.py --target=/content/mandala.jpg --project-in-wplus --num-steps=700 --network=/content/drive/MyDrive/CC3_stylegan/stylegan3-fun/training-runs/00018-stylegan3-t-shadow-1024x1024-gpus1-batch16-gamma32-resume_custom/network-snapshot-000072.pkl\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZR3uFQXnh9i0"
      },
      "outputs": [],
      "source": [
        "# Fine-tune StyleGAN3-R for MetFaces-U using 1 GPU, starting from the pre-trained FFHQ-U pickle.\n",
        "!python train.py --outdir=training-runs --cfg=stylegan3-t --data=/content/drive/MyDrive/CC3_stylegan/mandala_resized.zip \\\n",
        "    --gpus=1 --batch=16 --gamma=8 --mirror=1 --kimg=100 --snap=10 \\\n",
        "    --resume=https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan2/versions/1/files/stylegan2-afhqv2-512x512.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIVqS_PkpbIX"
      },
      "outputs": [],
      "source": [
        "!rm -rf /root/.cache/torch_extensions/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4LBfgXdozh_",
        "outputId": "cb8a434c-bc48-4fbe-8c39-801d20790efd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "00000-stylegan3-t-mandala512-gpus1-batch8-gamma4-resume_custom\n",
            "00001-stylegan3-t-mandala512-gpus1-batch8-gamma4-resume_custom\n",
            "00002-stylegan3-t-mandala512-gpus1-batch8-gamma4-resume_custom\n",
            "00003-stylegan3-t-mandala512-gpus1-batch8-gamma4-resume_custom\n",
            "00004-stylegan3-t-mandala512-gpus1-batch8-gamma4-resume_custom\n",
            "00005-stylegan3-t-mandala512-gpus1-batch8-gamma4-resume_custom\n",
            "00006-stylegan3-t-mandala512-gpus1-batch8-gamma4-resume_custom\n",
            "00007-stylegan3-t-mandala512-gpus1-batch8-gamma4-resume_custom\n",
            "00008-stylegan3-t-mandala512-gpus1-batch8-gamma4-resume_custom\n",
            "00009-stylegan3-t-mandala512-gpus1-batch8-gamma4-resume_custom\n",
            "00010-stylegan3-t-mandala512-gpus1-batch8-gamma4-resume_custom\n",
            "00011-stylegan3-t-mandala512-gpus1-batch8-gamma4-resume_custom\n",
            "00012-stylegan3-t-mandala512-gpus1-batch8-gamma4-resume_custom\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/MyDrive/CC3_stylegan/stylegan3-fun/training-runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqyGn-p8n0WI",
        "outputId": "1eb866bb-d241-4736-c90a-444c46fdd1a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.9/dist-packages (1.11.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install ninja"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "gpuClass": "premium"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}